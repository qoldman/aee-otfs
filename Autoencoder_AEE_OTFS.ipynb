{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d745c132"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Input, Lambda, BatchNormalization\n",
        "import scipy.io\n",
        "import time\n",
        "import matplotlib.pyplot as plt"
      ],
      "id": "d745c132"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b44926ea",
        "outputId": "505b417e-5cdb-47dd-dacf-1c98d91a70ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subblock length: 2\n",
            "Number of messages: 256\n",
            "Spectral efficiency: 4.0 (bits/s/Hz)\n"
          ]
        }
      ],
      "source": [
        "N = 2\n",
        "M = 2**(N*4)\n",
        "se = np.log2(M)/N\n",
        "Q = 128\n",
        "nBits = int(np.log2(M))\n",
        "\n",
        "print(\"Subblock length: \" + str(N))\n",
        "print(\"Number of messages: \" + str(M))\n",
        "print(\"Spectral efficiency: \" + str(se) + \" (bits/s/Hz)\")"
      ],
      "id": "b44926ea"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3bb1c9c4"
      },
      "outputs": [],
      "source": [
        "def real_to_complex(x):\n",
        "    real = x[:,0:int(int(x.shape[1])/2)]\n",
        "    imag = x[:,int(int(x.shape[1])/2):int(x.shape[1])]\n",
        "    return tf.dtypes.complex(real,imag)\n",
        "\n",
        "def channel(x):\n",
        "    SNRdB = 7\n",
        "    N0 = 1/(10**(SNRdB/10))\n",
        "    N0 = K.constant(N0, dtype='float32')\n",
        "\n",
        "    nR = K.random_normal(K.shape(x), mean=0, stddev=K.sqrt(N0/2))\n",
        "    nI = K.random_normal(K.shape(x), mean=0, stddev=K.sqrt(N0/2))\n",
        "    n = tf.dtypes.complex(nR,nI)\n",
        "\n",
        "    y = x + n\n",
        "\n",
        "    yR = tf.math.real(y)\n",
        "    yI = tf.math.imag(y)\n",
        "\n",
        "    return tf.concat([yR,yI],-1)"
      ],
      "id": "3bb1c9c4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bb990adc"
      },
      "outputs": [],
      "source": [
        "# ------------------------------------------ Encoder ---------------------------------------------\n",
        "input_signal = keras.Input(shape=(M,))\n",
        "encoded1 = layers.Dense(units=Q, activation='relu',name='ReLu_Layer1',kernel_initializer='normal')(input_signal)\n",
        "encoded2 = layers.Dense(units=2*N, activation='linear',name='Linear_Layer',kernel_initializer='normal')(encoded1)\n",
        "# encoded3 = Lambda(lambda x: x/tf.sqrt(2*tf.reduce_mean(tf.square(x))))(encoded2)\n",
        "encoded3 = Lambda(lambda x: np.sqrt(N)*K.l2_normalize(x, axis=1))(encoded2)\n",
        "Lambda1 = Lambda(real_to_complex)(encoded3)\n",
        "# ---------------------------------- Wireless Channel (y=Hx+n) -----------------------------------\n",
        "Lambda2 = Lambda(channel)(Lambda1)\n",
        "# ------------------------------------------ Decoder ---------------------------------------------\n",
        "decoded1 = layers.Dense(Q, activation='relu',name='ReLu_Layer2',kernel_initializer='normal')(Lambda2)\n",
        "decoded2 = layers.Dense(M, activation='softmax',name='softmax_Layer',kernel_initializer='normal')(decoded1)"
      ],
      "id": "bb990adc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b87a4862",
        "outputId": "6b5940e8-e061-4b94-acbd-a3134d275089"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 256)]             0         \n",
            "                                                                 \n",
            " ReLu_Layer1 (Dense)         (None, 128)               32896     \n",
            "                                                                 \n",
            " Linear_Layer (Dense)        (None, 4)                 516       \n",
            "                                                                 \n",
            " lambda_3 (Lambda)           (None, 4)                 0         \n",
            "                                                                 \n",
            " lambda_4 (Lambda)           (None, 2)                 0         \n",
            "                                                                 \n",
            " lambda_5 (Lambda)           (None, 4)                 0         \n",
            "                                                                 \n",
            " ReLu_Layer2 (Dense)         (None, 128)               640       \n",
            "                                                                 \n",
            " softmax_Layer (Dense)       (None, 256)               33024     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 67,076\n",
            "Trainable params: 67,076\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "autoencoder = keras.Model(input_signal, decoded2)\n",
        "opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
        "autoencoder.compile(optimizer=opt, loss='categorical_crossentropy')\n",
        "autoencoder.summary()"
      ],
      "id": "b87a4862"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "021b5986"
      },
      "outputs": [],
      "source": [
        "train_size = 100000\n",
        "x_train = np.zeros((train_size,M))\n",
        "J = np.random.choice(M, train_size)\n",
        "for i, j in enumerate(J):\n",
        "    x_train[i, j] = 1"
      ],
      "id": "021b5986"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "89860c93"
      },
      "outputs": [],
      "source": [
        "test_size = 10000\n",
        "x_test = np.zeros((test_size,M))\n",
        "J = np.random.choice(M, test_size)\n",
        "for i, j in enumerate(J):\n",
        "    x_test[i, j] = 1"
      ],
      "id": "89860c93"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95ece913",
        "outputId": "ec1dcf38-d0ee-458d-d9dd-21a51016edf8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "196/196 [==============================] - 3s 12ms/step - loss: 5.4768 - val_loss: 5.4014\n",
            "Epoch 2/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 5.2936 - val_loss: 5.1663\n",
            "Epoch 3/1000\n",
            "196/196 [==============================] - 3s 14ms/step - loss: 5.0156 - val_loss: 4.8549\n",
            "Epoch 4/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 4.6881 - val_loss: 4.5249\n",
            "Epoch 5/1000\n",
            "196/196 [==============================] - 3s 13ms/step - loss: 4.3663 - val_loss: 4.2140\n",
            "Epoch 6/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 4.0725 - val_loss: 3.9380\n",
            "Epoch 7/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 3.8207 - val_loss: 3.7099\n",
            "Epoch 8/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 3.6044 - val_loss: 3.5062\n",
            "Epoch 9/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 3.4246 - val_loss: 3.3437\n",
            "Epoch 10/1000\n",
            "196/196 [==============================] - 3s 13ms/step - loss: 3.2735 - val_loss: 3.2090\n",
            "Epoch 11/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 3.1428 - val_loss: 3.0887\n",
            "Epoch 12/1000\n",
            "196/196 [==============================] - 3s 14ms/step - loss: 3.0339 - val_loss: 2.9892\n",
            "Epoch 13/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.9387 - val_loss: 2.8967\n",
            "Epoch 14/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.8567 - val_loss: 2.8149\n",
            "Epoch 15/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.7816 - val_loss: 2.7438\n",
            "Epoch 16/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.7218 - val_loss: 2.6885\n",
            "Epoch 17/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.6629 - val_loss: 2.6302\n",
            "Epoch 18/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.6145 - val_loss: 2.5876\n",
            "Epoch 19/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.5691 - val_loss: 2.5353\n",
            "Epoch 20/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.5321 - val_loss: 2.5236\n",
            "Epoch 21/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.4984 - val_loss: 2.5030\n",
            "Epoch 22/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.4697 - val_loss: 2.4523\n",
            "Epoch 23/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.4430 - val_loss: 2.4362\n",
            "Epoch 24/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.4197 - val_loss: 2.3932\n",
            "Epoch 25/1000\n",
            "196/196 [==============================] - 3s 14ms/step - loss: 2.3952 - val_loss: 2.3999\n",
            "Epoch 26/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.3830 - val_loss: 2.3763\n",
            "Epoch 27/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.3638 - val_loss: 2.3533\n",
            "Epoch 28/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.3472 - val_loss: 2.3626\n",
            "Epoch 29/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.3360 - val_loss: 2.3297\n",
            "Epoch 30/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.3289 - val_loss: 2.3141\n",
            "Epoch 31/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.3145 - val_loss: 2.3123\n",
            "Epoch 32/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.3021 - val_loss: 2.2929\n",
            "Epoch 33/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2963 - val_loss: 2.2868\n",
            "Epoch 34/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2876 - val_loss: 2.2909\n",
            "Epoch 35/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2823 - val_loss: 2.2842\n",
            "Epoch 36/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2806 - val_loss: 2.2849\n",
            "Epoch 37/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2743 - val_loss: 2.2626\n",
            "Epoch 38/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2621 - val_loss: 2.2748\n",
            "Epoch 39/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2602 - val_loss: 2.2597\n",
            "Epoch 40/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2642 - val_loss: 2.2574\n",
            "Epoch 41/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2596 - val_loss: 2.2543\n",
            "Epoch 42/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2548 - val_loss: 2.2587\n",
            "Epoch 43/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2569 - val_loss: 2.2545\n",
            "Epoch 44/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2478 - val_loss: 2.2595\n",
            "Epoch 45/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2458 - val_loss: 2.2519\n",
            "Epoch 46/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2440 - val_loss: 2.2512\n",
            "Epoch 47/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2466 - val_loss: 2.2607\n",
            "Epoch 48/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2358 - val_loss: 2.2254\n",
            "Epoch 49/1000\n",
            "196/196 [==============================] - 2s 13ms/step - loss: 2.2482 - val_loss: 2.2376\n",
            "Epoch 50/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2457 - val_loss: 2.2428\n",
            "Epoch 51/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2432 - val_loss: 2.2574\n",
            "Epoch 52/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2442 - val_loss: 2.2465\n",
            "Epoch 53/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2420 - val_loss: 2.2604\n",
            "Epoch 54/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2342 - val_loss: 2.2261\n",
            "Epoch 55/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2376 - val_loss: 2.2503\n",
            "Epoch 56/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2349 - val_loss: 2.2452\n",
            "Epoch 57/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2339 - val_loss: 2.2412\n",
            "Epoch 58/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2372 - val_loss: 2.2289\n",
            "Epoch 59/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2399 - val_loss: 2.2540\n",
            "Epoch 60/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2317 - val_loss: 2.2519\n",
            "Epoch 61/1000\n",
            "196/196 [==============================] - 3s 14ms/step - loss: 2.2331 - val_loss: 2.2529\n",
            "Epoch 62/1000\n",
            "196/196 [==============================] - 3s 17ms/step - loss: 2.2344 - val_loss: 2.2558\n",
            "Epoch 63/1000\n",
            "196/196 [==============================] - 3s 13ms/step - loss: 2.2338 - val_loss: 2.2128\n",
            "Epoch 64/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2291 - val_loss: 2.2261\n",
            "Epoch 65/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2244 - val_loss: 2.2416\n",
            "Epoch 66/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2275 - val_loss: 2.2304\n",
            "Epoch 67/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2340 - val_loss: 2.2086\n",
            "Epoch 68/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2294 - val_loss: 2.2182\n",
            "Epoch 69/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2284 - val_loss: 2.2451\n",
            "Epoch 70/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2285 - val_loss: 2.2325\n",
            "Epoch 71/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2291 - val_loss: 2.2252\n",
            "Epoch 72/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2314 - val_loss: 2.2252\n",
            "Epoch 73/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2305 - val_loss: 2.2482\n",
            "Epoch 74/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2285 - val_loss: 2.2292\n",
            "Epoch 75/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2314 - val_loss: 2.2272\n",
            "Epoch 76/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2251 - val_loss: 2.2193\n",
            "Epoch 77/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2274 - val_loss: 2.2575\n",
            "Epoch 78/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2221 - val_loss: 2.2069\n",
            "Epoch 79/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2363 - val_loss: 2.2467\n",
            "Epoch 80/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2305 - val_loss: 2.2285\n",
            "Epoch 81/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2324 - val_loss: 2.2221\n",
            "Epoch 82/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2303 - val_loss: 2.2174\n",
            "Epoch 83/1000\n",
            "196/196 [==============================] - 3s 14ms/step - loss: 2.2278 - val_loss: 2.2148\n",
            "Epoch 84/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2280 - val_loss: 2.2249\n",
            "Epoch 85/1000\n",
            "196/196 [==============================] - 3s 13ms/step - loss: 2.2261 - val_loss: 2.2216\n",
            "Epoch 86/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2328 - val_loss: 2.2291\n",
            "Epoch 87/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2246 - val_loss: 2.2195\n",
            "Epoch 88/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2268 - val_loss: 2.2219\n",
            "Epoch 89/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2290 - val_loss: 2.2240\n",
            "Epoch 90/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2272 - val_loss: 2.2259\n",
            "Epoch 91/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2261 - val_loss: 2.2084\n",
            "Epoch 92/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2246 - val_loss: 2.2007\n",
            "Epoch 93/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2313 - val_loss: 2.2309\n",
            "Epoch 94/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2291 - val_loss: 2.2565\n",
            "Epoch 95/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2240 - val_loss: 2.2293\n",
            "Epoch 96/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2322 - val_loss: 2.2296\n",
            "Epoch 97/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2273 - val_loss: 2.2057\n",
            "Epoch 98/1000\n",
            "196/196 [==============================] - 3s 14ms/step - loss: 2.2316 - val_loss: 2.2162\n",
            "Epoch 99/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2273 - val_loss: 2.2356\n",
            "Epoch 100/1000\n",
            "196/196 [==============================] - 3s 13ms/step - loss: 2.2244 - val_loss: 2.2169\n",
            "Epoch 101/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2237 - val_loss: 2.2336\n",
            "Epoch 102/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2310 - val_loss: 2.2196\n",
            "Epoch 103/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2289 - val_loss: 2.2181\n",
            "Epoch 104/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2288 - val_loss: 2.2327\n",
            "Epoch 105/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2288 - val_loss: 2.2128\n",
            "Epoch 106/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2286 - val_loss: 2.2342\n",
            "Epoch 107/1000\n",
            "196/196 [==============================] - 3s 14ms/step - loss: 2.2186 - val_loss: 2.2348\n",
            "Epoch 108/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2213 - val_loss: 2.2413\n",
            "Epoch 109/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2308 - val_loss: 2.2208\n",
            "Epoch 110/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2260 - val_loss: 2.2426\n",
            "Epoch 111/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2279 - val_loss: 2.2259\n",
            "Epoch 112/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2257 - val_loss: 2.2065\n",
            "Epoch 113/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2245 - val_loss: 2.2281\n",
            "Epoch 114/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2327 - val_loss: 2.2006\n",
            "Epoch 115/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2219 - val_loss: 2.2253\n",
            "Epoch 116/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2227 - val_loss: 2.2580\n",
            "Epoch 117/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2249 - val_loss: 2.2183\n",
            "Epoch 118/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2206 - val_loss: 2.2245\n",
            "Epoch 119/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2233 - val_loss: 2.2324\n",
            "Epoch 120/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2213 - val_loss: 2.2454\n",
            "Epoch 121/1000\n",
            "196/196 [==============================] - 3s 17ms/step - loss: 2.2245 - val_loss: 2.2148\n",
            "Epoch 122/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2208 - val_loss: 2.2159\n",
            "Epoch 123/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2252 - val_loss: 2.2424\n",
            "Epoch 124/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2217 - val_loss: 2.2282\n",
            "Epoch 125/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2238 - val_loss: 2.2316\n",
            "Epoch 126/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2285 - val_loss: 2.2120\n",
            "Epoch 127/1000\n",
            "196/196 [==============================] - 3s 14ms/step - loss: 2.2215 - val_loss: 2.2249\n",
            "Epoch 128/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2228 - val_loss: 2.2290\n",
            "Epoch 129/1000\n",
            "196/196 [==============================] - 3s 13ms/step - loss: 2.2264 - val_loss: 2.2188\n",
            "Epoch 130/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2186 - val_loss: 2.2279\n",
            "Epoch 131/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2170 - val_loss: 2.2096\n",
            "Epoch 132/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2335 - val_loss: 2.2041\n",
            "Epoch 133/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2247 - val_loss: 2.2236\n",
            "Epoch 134/1000\n",
            "196/196 [==============================] - 2s 13ms/step - loss: 2.2276 - val_loss: 2.2375\n",
            "Epoch 135/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2176 - val_loss: 2.2063\n",
            "Epoch 136/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2216 - val_loss: 2.2109\n",
            "Epoch 137/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2199 - val_loss: 2.2372\n",
            "Epoch 138/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2147 - val_loss: 2.2177\n",
            "Epoch 139/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2248 - val_loss: 2.2183\n",
            "Epoch 140/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2232 - val_loss: 2.2201\n",
            "Epoch 141/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2240 - val_loss: 2.2187\n",
            "Epoch 142/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2248 - val_loss: 2.2204\n",
            "Epoch 143/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2260 - val_loss: 2.2480\n",
            "Epoch 144/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2245 - val_loss: 2.2209\n",
            "Epoch 145/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2229 - val_loss: 2.2063\n",
            "Epoch 146/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2201 - val_loss: 2.2123\n",
            "Epoch 147/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2260 - val_loss: 2.2256\n",
            "Epoch 148/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2211 - val_loss: 2.2298\n",
            "Epoch 149/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2232 - val_loss: 2.2290\n",
            "Epoch 150/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2225 - val_loss: 2.1935\n",
            "Epoch 151/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2204 - val_loss: 2.2274\n",
            "Epoch 152/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2215 - val_loss: 2.2245\n",
            "Epoch 153/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2198 - val_loss: 2.2101\n",
            "Epoch 154/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2224 - val_loss: 2.2318\n",
            "Epoch 155/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2231 - val_loss: 2.2210\n",
            "Epoch 156/1000\n",
            "196/196 [==============================] - 3s 13ms/step - loss: 2.2250 - val_loss: 2.2224\n",
            "Epoch 157/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2212 - val_loss: 2.2349\n",
            "Epoch 158/1000\n",
            "196/196 [==============================] - 3s 14ms/step - loss: 2.2126 - val_loss: 2.2158\n",
            "Epoch 159/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2211 - val_loss: 2.2310\n",
            "Epoch 160/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2274 - val_loss: 2.2177\n",
            "Epoch 161/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2275 - val_loss: 2.2207\n",
            "Epoch 162/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2267 - val_loss: 2.2328\n",
            "Epoch 163/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2284 - val_loss: 2.2233\n",
            "Epoch 164/1000\n",
            "196/196 [==============================] - 3s 17ms/step - loss: 2.2199 - val_loss: 2.2256\n",
            "Epoch 165/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2161 - val_loss: 2.2160\n",
            "Epoch 166/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2296 - val_loss: 2.2183\n",
            "Epoch 167/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2250 - val_loss: 2.2193\n",
            "Epoch 168/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2197 - val_loss: 2.2064\n",
            "Epoch 169/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2222 - val_loss: 2.2411\n",
            "Epoch 170/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2254 - val_loss: 2.2302\n",
            "Epoch 171/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2209 - val_loss: 2.2171\n",
            "Epoch 172/1000\n",
            "196/196 [==============================] - 3s 17ms/step - loss: 2.2179 - val_loss: 2.2219\n",
            "Epoch 173/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2232 - val_loss: 2.2164\n",
            "Epoch 174/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2240 - val_loss: 2.2087\n",
            "Epoch 175/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2245 - val_loss: 2.2286\n",
            "Epoch 176/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2200 - val_loss: 2.2094\n",
            "Epoch 177/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2225 - val_loss: 2.2203\n",
            "Epoch 178/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2203 - val_loss: 2.2250\n",
            "Epoch 179/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2220 - val_loss: 2.2213\n",
            "Epoch 180/1000\n",
            "196/196 [==============================] - 3s 13ms/step - loss: 2.2251 - val_loss: 2.2257\n",
            "Epoch 181/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2210 - val_loss: 2.2377\n",
            "Epoch 182/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2203 - val_loss: 2.2205\n",
            "Epoch 183/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2231 - val_loss: 2.2116\n",
            "Epoch 184/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2240 - val_loss: 2.2220\n",
            "Epoch 185/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2197 - val_loss: 2.2303\n",
            "Epoch 186/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2317 - val_loss: 2.2258\n",
            "Epoch 187/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2202 - val_loss: 2.2118\n",
            "Epoch 188/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2223 - val_loss: 2.2131\n",
            "Epoch 189/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2218 - val_loss: 2.2290\n",
            "Epoch 190/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2205 - val_loss: 2.2140\n",
            "Epoch 191/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2233 - val_loss: 2.2366\n",
            "Epoch 192/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2219 - val_loss: 2.2272\n",
            "Epoch 193/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2193 - val_loss: 2.2356\n",
            "Epoch 194/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2238 - val_loss: 2.2346\n",
            "Epoch 195/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2256 - val_loss: 2.2145\n",
            "Epoch 196/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2269 - val_loss: 2.2011\n",
            "Epoch 197/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2173 - val_loss: 2.2269\n",
            "Epoch 198/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2232 - val_loss: 2.2151\n",
            "Epoch 199/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2182 - val_loss: 2.2443\n",
            "Epoch 200/1000\n",
            "196/196 [==============================] - 2s 13ms/step - loss: 2.2224 - val_loss: 2.2342\n",
            "Epoch 201/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2210 - val_loss: 2.2440\n",
            "Epoch 202/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2196 - val_loss: 2.2305\n",
            "Epoch 203/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2192 - val_loss: 2.2181\n",
            "Epoch 204/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2264 - val_loss: 2.2159\n",
            "Epoch 205/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2190 - val_loss: 2.2345\n",
            "Epoch 206/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2201 - val_loss: 2.2231\n",
            "Epoch 207/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2238 - val_loss: 2.2367\n",
            "Epoch 208/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2195 - val_loss: 2.2257\n",
            "Epoch 209/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2208 - val_loss: 2.2282\n",
            "Epoch 210/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2235 - val_loss: 2.2086\n",
            "Epoch 211/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2167 - val_loss: 2.2194\n",
            "Epoch 212/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2210 - val_loss: 2.2037\n",
            "Epoch 213/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2229 - val_loss: 2.2358\n",
            "Epoch 214/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2248 - val_loss: 2.2151\n",
            "Epoch 215/1000\n",
            "196/196 [==============================] - 3s 14ms/step - loss: 2.2200 - val_loss: 2.2198\n",
            "Epoch 216/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2153 - val_loss: 2.2447\n",
            "Epoch 217/1000\n",
            "196/196 [==============================] - 3s 13ms/step - loss: 2.2239 - val_loss: 2.2179\n",
            "Epoch 218/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2143 - val_loss: 2.2284\n",
            "Epoch 219/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2244 - val_loss: 2.2124\n",
            "Epoch 220/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2206 - val_loss: 2.2316\n",
            "Epoch 221/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2146 - val_loss: 2.2188\n",
            "Epoch 222/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2212 - val_loss: 2.2488\n",
            "Epoch 223/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2175 - val_loss: 2.2030\n",
            "Epoch 224/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2246 - val_loss: 2.2406\n",
            "Epoch 225/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2197 - val_loss: 2.2234\n",
            "Epoch 226/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2202 - val_loss: 2.1964\n",
            "Epoch 227/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2163 - val_loss: 2.2313\n",
            "Epoch 228/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2152 - val_loss: 2.1981\n",
            "Epoch 229/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2184 - val_loss: 2.2173\n",
            "Epoch 230/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2219 - val_loss: 2.2260\n",
            "Epoch 231/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2141 - val_loss: 2.2272\n",
            "Epoch 232/1000\n",
            "196/196 [==============================] - 3s 13ms/step - loss: 2.2129 - val_loss: 2.2160\n",
            "Epoch 233/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2260 - val_loss: 2.2065\n",
            "Epoch 234/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2159 - val_loss: 2.2249\n",
            "Epoch 235/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2176 - val_loss: 2.2462\n",
            "Epoch 236/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2160 - val_loss: 2.2285\n",
            "Epoch 237/1000\n",
            "196/196 [==============================] - 2s 13ms/step - loss: 2.2245 - val_loss: 2.2229\n",
            "Epoch 238/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2175 - val_loss: 2.2214\n",
            "Epoch 239/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2113 - val_loss: 2.2136\n",
            "Epoch 240/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2230 - val_loss: 2.2338\n",
            "Epoch 241/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2230 - val_loss: 2.2268\n",
            "Epoch 242/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2252 - val_loss: 2.2030\n",
            "Epoch 243/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2206 - val_loss: 2.2298\n",
            "Epoch 244/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2167 - val_loss: 2.2295\n",
            "Epoch 245/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2153 - val_loss: 2.2156\n",
            "Epoch 246/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2169 - val_loss: 2.2231\n",
            "Epoch 247/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2256 - val_loss: 2.2544\n",
            "Epoch 248/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2201 - val_loss: 2.2370\n",
            "Epoch 249/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2135 - val_loss: 2.2255\n",
            "Epoch 250/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2276 - val_loss: 2.2409\n",
            "Epoch 251/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2213 - val_loss: 2.2197\n",
            "Epoch 252/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2214 - val_loss: 2.2199\n",
            "Epoch 253/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2200 - val_loss: 2.2232\n",
            "Epoch 254/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2214 - val_loss: 2.2506\n",
            "Epoch 255/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2160 - val_loss: 2.1986\n",
            "Epoch 256/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2222 - val_loss: 2.2174\n",
            "Epoch 257/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2167 - val_loss: 2.2087\n",
            "Epoch 258/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2264 - val_loss: 2.1969\n",
            "Epoch 259/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2231 - val_loss: 2.2109\n",
            "Epoch 260/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2226 - val_loss: 2.2322\n",
            "Epoch 261/1000\n",
            "196/196 [==============================] - 2s 13ms/step - loss: 2.2158 - val_loss: 2.2370\n",
            "Epoch 262/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2150 - val_loss: 2.2207\n",
            "Epoch 263/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2161 - val_loss: 2.2593\n",
            "Epoch 264/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2221 - val_loss: 2.2032\n",
            "Epoch 265/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2182 - val_loss: 2.2346\n",
            "Epoch 266/1000\n",
            "196/196 [==============================] - 3s 14ms/step - loss: 2.2172 - val_loss: 2.2269\n",
            "Epoch 267/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2156 - val_loss: 2.2325\n",
            "Epoch 268/1000\n",
            "196/196 [==============================] - 3s 14ms/step - loss: 2.2158 - val_loss: 2.2105\n",
            "Epoch 269/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2147 - val_loss: 2.2249\n",
            "Epoch 270/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2165 - val_loss: 2.2292\n",
            "Epoch 271/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2148 - val_loss: 2.2344\n",
            "Epoch 272/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2187 - val_loss: 2.2399\n",
            "Epoch 273/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2168 - val_loss: 2.2203\n",
            "Epoch 274/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2150 - val_loss: 2.2101\n",
            "Epoch 275/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2184 - val_loss: 2.2303\n",
            "Epoch 276/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2176 - val_loss: 2.2328\n",
            "Epoch 277/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2253 - val_loss: 2.2108\n",
            "Epoch 278/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2151 - val_loss: 2.2121\n",
            "Epoch 279/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2188 - val_loss: 2.2095\n",
            "Epoch 280/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2223 - val_loss: 2.2233\n",
            "Epoch 281/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2157 - val_loss: 2.2036\n",
            "Epoch 282/1000\n",
            "196/196 [==============================] - 3s 17ms/step - loss: 2.2253 - val_loss: 2.2404\n",
            "Epoch 283/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2172 - val_loss: 2.2117\n",
            "Epoch 284/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2326 - val_loss: 2.2506\n",
            "Epoch 285/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2129 - val_loss: 2.2055\n",
            "Epoch 286/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2149 - val_loss: 2.2355\n",
            "Epoch 287/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2123 - val_loss: 2.2152\n",
            "Epoch 288/1000\n",
            "196/196 [==============================] - 3s 17ms/step - loss: 2.2213 - val_loss: 2.2213\n",
            "Epoch 289/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2187 - val_loss: 2.2426\n",
            "Epoch 290/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2155 - val_loss: 2.2435\n",
            "Epoch 291/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2171 - val_loss: 2.2276\n",
            "Epoch 292/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2242 - val_loss: 2.2118\n",
            "Epoch 293/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2152 - val_loss: 2.2338\n",
            "Epoch 294/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2157 - val_loss: 2.2311\n",
            "Epoch 295/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2156 - val_loss: 2.2121\n",
            "Epoch 296/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2274 - val_loss: 2.2183\n",
            "Epoch 297/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2194 - val_loss: 2.2235\n",
            "Epoch 298/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2159 - val_loss: 2.2195\n",
            "Epoch 299/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2180 - val_loss: 2.2256\n",
            "Epoch 300/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2134 - val_loss: 2.2184\n",
            "Epoch 301/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2179 - val_loss: 2.2187\n",
            "Epoch 302/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2172 - val_loss: 2.2465\n",
            "Epoch 303/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2180 - val_loss: 2.2145\n",
            "Epoch 304/1000\n",
            "196/196 [==============================] - 3s 14ms/step - loss: 2.2195 - val_loss: 2.2255\n",
            "Epoch 305/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2234 - val_loss: 2.2097\n",
            "Epoch 306/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2247 - val_loss: 2.2152\n",
            "Epoch 307/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2177 - val_loss: 2.2279\n",
            "Epoch 308/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2247 - val_loss: 2.2104\n",
            "Epoch 309/1000\n",
            "196/196 [==============================] - 2s 13ms/step - loss: 2.2253 - val_loss: 2.2137\n",
            "Epoch 310/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2185 - val_loss: 2.2168\n",
            "Epoch 311/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2168 - val_loss: 2.2361\n",
            "Epoch 312/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2173 - val_loss: 2.2163\n",
            "Epoch 313/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2181 - val_loss: 2.2238\n",
            "Epoch 314/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2171 - val_loss: 2.2171\n",
            "Epoch 315/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2224 - val_loss: 2.2294\n",
            "Epoch 316/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2181 - val_loss: 2.2345\n",
            "Epoch 317/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2191 - val_loss: 2.2165\n",
            "Epoch 318/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2154 - val_loss: 2.2320\n",
            "Epoch 319/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2143 - val_loss: 2.2029\n",
            "Epoch 320/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2134 - val_loss: 2.2133\n",
            "Epoch 321/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2236 - val_loss: 2.2237\n",
            "Epoch 322/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2244 - val_loss: 2.2074\n",
            "Epoch 323/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2200 - val_loss: 2.2197\n",
            "Epoch 324/1000\n",
            "196/196 [==============================] - 3s 13ms/step - loss: 2.2210 - val_loss: 2.2257\n",
            "Epoch 325/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2198 - val_loss: 2.2212\n",
            "Epoch 326/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2180 - val_loss: 2.2037\n",
            "Epoch 327/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2228 - val_loss: 2.2197\n",
            "Epoch 328/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2187 - val_loss: 2.2051\n",
            "Epoch 329/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2162 - val_loss: 2.2406\n",
            "Epoch 330/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2183 - val_loss: 2.2345\n",
            "Epoch 331/1000\n",
            "196/196 [==============================] - 3s 13ms/step - loss: 2.2169 - val_loss: 2.2283\n",
            "Epoch 332/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2197 - val_loss: 2.2302\n",
            "Epoch 333/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2176 - val_loss: 2.2013\n",
            "Epoch 334/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2186 - val_loss: 2.2292\n",
            "Epoch 335/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2219 - val_loss: 2.2383\n",
            "Epoch 336/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2202 - val_loss: 2.2343\n",
            "Epoch 337/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2252 - val_loss: 2.2168\n",
            "Epoch 338/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2165 - val_loss: 2.2046\n",
            "Epoch 339/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2174 - val_loss: 2.2128\n",
            "Epoch 340/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2190 - val_loss: 2.2062\n",
            "Epoch 341/1000\n",
            "196/196 [==============================] - 2s 13ms/step - loss: 2.2186 - val_loss: 2.2174\n",
            "Epoch 342/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2195 - val_loss: 2.2385\n",
            "Epoch 343/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2204 - val_loss: 2.2296\n",
            "Epoch 344/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2239 - val_loss: 2.2320\n",
            "Epoch 345/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2173 - val_loss: 2.2099\n",
            "Epoch 346/1000\n",
            "196/196 [==============================] - 3s 14ms/step - loss: 2.2175 - val_loss: 2.2274\n",
            "Epoch 347/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2195 - val_loss: 2.2147\n",
            "Epoch 348/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2241 - val_loss: 2.2067\n",
            "Epoch 349/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2157 - val_loss: 2.2184\n",
            "Epoch 350/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2124 - val_loss: 2.2099\n",
            "Epoch 351/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2167 - val_loss: 2.2192\n",
            "Epoch 352/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2208 - val_loss: 2.2072\n",
            "Epoch 353/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2217 - val_loss: 2.2221\n",
            "Epoch 354/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2134 - val_loss: 2.2182\n",
            "Epoch 355/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2241 - val_loss: 2.2251\n",
            "Epoch 356/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2130 - val_loss: 2.2284\n",
            "Epoch 357/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2187 - val_loss: 2.2491\n",
            "Epoch 358/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2194 - val_loss: 2.2273\n",
            "Epoch 359/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2149 - val_loss: 2.2032\n",
            "Epoch 360/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2174 - val_loss: 2.2235\n",
            "Epoch 361/1000\n",
            "196/196 [==============================] - 3s 14ms/step - loss: 2.2179 - val_loss: 2.2165\n",
            "Epoch 362/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2174 - val_loss: 2.2263\n",
            "Epoch 363/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2240 - val_loss: 2.2096\n",
            "Epoch 364/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2105 - val_loss: 2.2311\n",
            "Epoch 365/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2194 - val_loss: 2.2161\n",
            "Epoch 366/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2177 - val_loss: 2.2319\n",
            "Epoch 367/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2143 - val_loss: 2.2185\n",
            "Epoch 368/1000\n",
            "196/196 [==============================] - 3s 13ms/step - loss: 2.2133 - val_loss: 2.1962\n",
            "Epoch 369/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2158 - val_loss: 2.2238\n",
            "Epoch 370/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2137 - val_loss: 2.2036\n",
            "Epoch 371/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2135 - val_loss: 2.2192\n",
            "Epoch 372/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2172 - val_loss: 2.2146\n",
            "Epoch 373/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2188 - val_loss: 2.2139\n",
            "Epoch 374/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2238 - val_loss: 2.2159\n",
            "Epoch 375/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2218 - val_loss: 2.2077\n",
            "Epoch 376/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2253 - val_loss: 2.2129\n",
            "Epoch 377/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2224 - val_loss: 2.2182\n",
            "Epoch 378/1000\n",
            "196/196 [==============================] - 3s 13ms/step - loss: 2.2072 - val_loss: 2.2377\n",
            "Epoch 379/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2206 - val_loss: 2.2233\n",
            "Epoch 380/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2177 - val_loss: 2.2299\n",
            "Epoch 381/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2171 - val_loss: 2.2361\n",
            "Epoch 382/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2175 - val_loss: 2.2016\n",
            "Epoch 383/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2236 - val_loss: 2.2137\n",
            "Epoch 384/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2157 - val_loss: 2.2369\n",
            "Epoch 385/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2238 - val_loss: 2.2077\n",
            "Epoch 386/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2172 - val_loss: 2.2131\n",
            "Epoch 387/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2214 - val_loss: 2.1973\n",
            "Epoch 388/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2229 - val_loss: 2.2028\n",
            "Epoch 389/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2187 - val_loss: 2.2062\n",
            "Epoch 390/1000\n",
            "196/196 [==============================] - 3s 14ms/step - loss: 2.2147 - val_loss: 2.2189\n",
            "Epoch 391/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2156 - val_loss: 2.2062\n",
            "Epoch 392/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2181 - val_loss: 2.2272\n",
            "Epoch 393/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2189 - val_loss: 2.2022\n",
            "Epoch 394/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2202 - val_loss: 2.2300\n",
            "Epoch 395/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2105 - val_loss: 2.1975\n",
            "Epoch 396/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2141 - val_loss: 2.2425\n",
            "Epoch 397/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2187 - val_loss: 2.2234\n",
            "Epoch 398/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2102 - val_loss: 2.1990\n",
            "Epoch 399/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2165 - val_loss: 2.2380\n",
            "Epoch 400/1000\n",
            "196/196 [==============================] - 3s 13ms/step - loss: 2.2193 - val_loss: 2.2048\n",
            "Epoch 401/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2179 - val_loss: 2.2463\n",
            "Epoch 402/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2149 - val_loss: 2.2109\n",
            "Epoch 403/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2240 - val_loss: 2.2301\n",
            "Epoch 404/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2097 - val_loss: 2.2207\n",
            "Epoch 405/1000\n",
            "196/196 [==============================] - 3s 14ms/step - loss: 2.2146 - val_loss: 2.2200\n",
            "Epoch 406/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2094 - val_loss: 2.2048\n",
            "Epoch 407/1000\n",
            "196/196 [==============================] - 3s 14ms/step - loss: 2.2221 - val_loss: 2.2653\n",
            "Epoch 408/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2167 - val_loss: 2.2195\n",
            "Epoch 409/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2133 - val_loss: 2.2294\n",
            "Epoch 410/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2179 - val_loss: 2.2291\n",
            "Epoch 411/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2201 - val_loss: 2.2045\n",
            "Epoch 412/1000\n",
            "196/196 [==============================] - 2s 13ms/step - loss: 2.2147 - val_loss: 2.2202\n",
            "Epoch 413/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2142 - val_loss: 2.2161\n",
            "Epoch 414/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2212 - val_loss: 2.2285\n",
            "Epoch 415/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2123 - val_loss: 2.2115\n",
            "Epoch 416/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2172 - val_loss: 2.1966\n",
            "Epoch 417/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2142 - val_loss: 2.2128\n",
            "Epoch 418/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2190 - val_loss: 2.2066\n",
            "Epoch 419/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2172 - val_loss: 2.2113\n",
            "Epoch 420/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2160 - val_loss: 2.2104\n",
            "Epoch 421/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2168 - val_loss: 2.2093\n",
            "Epoch 422/1000\n",
            "196/196 [==============================] - 3s 13ms/step - loss: 2.2193 - val_loss: 2.2280\n",
            "Epoch 423/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2180 - val_loss: 2.2211\n",
            "Epoch 424/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2157 - val_loss: 2.2204\n",
            "Epoch 425/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2152 - val_loss: 2.2122\n",
            "Epoch 426/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2161 - val_loss: 2.2238\n",
            "Epoch 427/1000\n",
            "196/196 [==============================] - 3s 14ms/step - loss: 2.2165 - val_loss: 2.2265\n",
            "Epoch 428/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2136 - val_loss: 2.2293\n",
            "Epoch 429/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2196 - val_loss: 2.2001\n",
            "Epoch 430/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2165 - val_loss: 2.2157\n",
            "Epoch 431/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2129 - val_loss: 2.2150\n",
            "Epoch 432/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2152 - val_loss: 2.2065\n",
            "Epoch 433/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2238 - val_loss: 2.2176\n",
            "Epoch 434/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2220 - val_loss: 2.2389\n",
            "Epoch 435/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2176 - val_loss: 2.2087\n",
            "Epoch 436/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2123 - val_loss: 2.2034\n",
            "Epoch 437/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2145 - val_loss: 2.2013\n",
            "Epoch 438/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2152 - val_loss: 2.2202\n",
            "Epoch 439/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2174 - val_loss: 2.2054\n",
            "Epoch 440/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2136 - val_loss: 2.2135\n",
            "Epoch 441/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2130 - val_loss: 2.2215\n",
            "Epoch 442/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2218 - val_loss: 2.2416\n",
            "Epoch 443/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2233 - val_loss: 2.2238\n",
            "Epoch 444/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2158 - val_loss: 2.2245\n",
            "Epoch 445/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2167 - val_loss: 2.2057\n",
            "Epoch 446/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2190 - val_loss: 2.2140\n",
            "Epoch 447/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2156 - val_loss: 2.2339\n",
            "Epoch 448/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2261 - val_loss: 2.2172\n",
            "Epoch 449/1000\n",
            "196/196 [==============================] - 2s 13ms/step - loss: 2.2126 - val_loss: 2.2186\n",
            "Epoch 450/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2176 - val_loss: 2.2261\n",
            "Epoch 451/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2157 - val_loss: 2.2152\n",
            "Epoch 452/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2208 - val_loss: 2.2240\n",
            "Epoch 453/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2188 - val_loss: 2.2361\n",
            "Epoch 454/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2191 - val_loss: 2.2176\n",
            "Epoch 455/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2189 - val_loss: 2.2373\n",
            "Epoch 456/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2241 - val_loss: 2.1897\n",
            "Epoch 457/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2164 - val_loss: 2.2142\n",
            "Epoch 458/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2196 - val_loss: 2.2241\n",
            "Epoch 459/1000\n",
            "196/196 [==============================] - 3s 14ms/step - loss: 2.2150 - val_loss: 2.2471\n",
            "Epoch 460/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2234 - val_loss: 2.2169\n",
            "Epoch 461/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2172 - val_loss: 2.2279\n",
            "Epoch 462/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2170 - val_loss: 2.2225\n",
            "Epoch 463/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2103 - val_loss: 2.1962\n",
            "Epoch 464/1000\n",
            "196/196 [==============================] - 3s 14ms/step - loss: 2.2186 - val_loss: 2.2083\n",
            "Epoch 465/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2240 - val_loss: 2.2172\n",
            "Epoch 466/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2210 - val_loss: 2.2049\n",
            "Epoch 467/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2187 - val_loss: 2.2174\n",
            "Epoch 468/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2125 - val_loss: 2.2240\n",
            "Epoch 469/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2288 - val_loss: 2.2159\n",
            "Epoch 470/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2226 - val_loss: 2.2444\n",
            "Epoch 471/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2156 - val_loss: 2.2114\n",
            "Epoch 472/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2113 - val_loss: 2.2094\n",
            "Epoch 473/1000\n",
            "196/196 [==============================] - 3s 17ms/step - loss: 2.2226 - val_loss: 2.2207\n",
            "Epoch 474/1000\n",
            "196/196 [==============================] - 3s 13ms/step - loss: 2.2203 - val_loss: 2.2376\n",
            "Epoch 475/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2194 - val_loss: 2.2073\n",
            "Epoch 476/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2091 - val_loss: 2.2245\n",
            "Epoch 477/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2118 - val_loss: 2.2211\n",
            "Epoch 478/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2213 - val_loss: 2.2245\n",
            "Epoch 479/1000\n",
            "196/196 [==============================] - 3s 14ms/step - loss: 2.2114 - val_loss: 2.2325\n",
            "Epoch 480/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2226 - val_loss: 2.2324\n",
            "Epoch 481/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2186 - val_loss: 2.2242\n",
            "Epoch 482/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2177 - val_loss: 2.2200\n",
            "Epoch 483/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2131 - val_loss: 2.1953\n",
            "Epoch 484/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2174 - val_loss: 2.2390\n",
            "Epoch 485/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2167 - val_loss: 2.2240\n",
            "Epoch 486/1000\n",
            "196/196 [==============================] - 3s 13ms/step - loss: 2.2181 - val_loss: 2.2239\n",
            "Epoch 487/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2112 - val_loss: 2.2343\n",
            "Epoch 488/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2159 - val_loss: 2.2340\n",
            "Epoch 489/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2172 - val_loss: 2.2198\n",
            "Epoch 490/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2184 - val_loss: 2.2182\n",
            "Epoch 491/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2150 - val_loss: 2.2260\n",
            "Epoch 492/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2201 - val_loss: 2.2326\n",
            "Epoch 493/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2157 - val_loss: 2.2147\n",
            "Epoch 494/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2155 - val_loss: 2.2208\n",
            "Epoch 495/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2171 - val_loss: 2.2246\n",
            "Epoch 496/1000\n",
            "196/196 [==============================] - 3s 14ms/step - loss: 2.2157 - val_loss: 2.2075\n",
            "Epoch 497/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2180 - val_loss: 2.2409\n",
            "Epoch 498/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2214 - val_loss: 2.2145\n",
            "Epoch 499/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2242 - val_loss: 2.2170\n",
            "Epoch 500/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2132 - val_loss: 2.1895\n",
            "Epoch 501/1000\n",
            "196/196 [==============================] - 3s 14ms/step - loss: 2.2164 - val_loss: 2.2056\n",
            "Epoch 502/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2165 - val_loss: 2.2164\n",
            "Epoch 503/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2156 - val_loss: 2.2283\n",
            "Epoch 504/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2110 - val_loss: 2.2009\n",
            "Epoch 505/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2176 - val_loss: 2.2226\n",
            "Epoch 506/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2155 - val_loss: 2.2004\n",
            "Epoch 507/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2128 - val_loss: 2.2064\n",
            "Epoch 508/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2189 - val_loss: 2.2107\n",
            "Epoch 509/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2192 - val_loss: 2.2401\n",
            "Epoch 510/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2210 - val_loss: 2.2261\n",
            "Epoch 511/1000\n",
            "196/196 [==============================] - 3s 13ms/step - loss: 2.2166 - val_loss: 2.2383\n",
            "Epoch 512/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2169 - val_loss: 2.2219\n",
            "Epoch 513/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2187 - val_loss: 2.2276\n",
            "Epoch 514/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2204 - val_loss: 2.2169\n",
            "Epoch 515/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2148 - val_loss: 2.2097\n",
            "Epoch 516/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2207 - val_loss: 2.2162\n",
            "Epoch 517/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2214 - val_loss: 2.2286\n",
            "Epoch 518/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2140 - val_loss: 2.2219\n",
            "Epoch 519/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2146 - val_loss: 2.2210\n",
            "Epoch 520/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2152 - val_loss: 2.2306\n",
            "Epoch 521/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2208 - val_loss: 2.2098\n",
            "Epoch 522/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2196 - val_loss: 2.2478\n",
            "Epoch 523/1000\n",
            "196/196 [==============================] - 3s 14ms/step - loss: 2.2214 - val_loss: 2.2203\n",
            "Epoch 524/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2157 - val_loss: 2.2037\n",
            "Epoch 525/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2186 - val_loss: 2.2132\n",
            "Epoch 526/1000\n",
            "196/196 [==============================] - 2s 13ms/step - loss: 2.2166 - val_loss: 2.2287\n",
            "Epoch 527/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2214 - val_loss: 2.2299\n",
            "Epoch 528/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2176 - val_loss: 2.2088\n",
            "Epoch 529/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2116 - val_loss: 2.2219\n",
            "Epoch 530/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2167 - val_loss: 2.2108\n",
            "Epoch 531/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2199 - val_loss: 2.2152\n",
            "Epoch 532/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2115 - val_loss: 2.2291\n",
            "Epoch 533/1000\n",
            "196/196 [==============================] - 3s 14ms/step - loss: 2.2150 - val_loss: 2.1995\n",
            "Epoch 534/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2136 - val_loss: 2.2295\n",
            "Epoch 535/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2082 - val_loss: 2.2316\n",
            "Epoch 536/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2100 - val_loss: 2.2118\n",
            "Epoch 537/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2128 - val_loss: 2.2089\n",
            "Epoch 538/1000\n",
            "196/196 [==============================] - 3s 14ms/step - loss: 2.2232 - val_loss: 2.2305\n",
            "Epoch 539/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2162 - val_loss: 2.2155\n",
            "Epoch 540/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2197 - val_loss: 2.2031\n",
            "Epoch 541/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2146 - val_loss: 2.2240\n",
            "Epoch 542/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2151 - val_loss: 2.2062\n",
            "Epoch 543/1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2172 - val_loss: 2.2277\n",
            "Epoch 544/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2136 - val_loss: 2.2018\n",
            "Epoch 545/1000\n",
            "196/196 [==============================] - 3s 13ms/step - loss: 2.2190 - val_loss: 2.2092\n",
            "Epoch 546/1000\n",
            "196/196 [==============================] - 3s 17ms/step - loss: 2.2164 - val_loss: 2.2068\n",
            "Epoch 547/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2195 - val_loss: 2.1850\n",
            "Epoch 548/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2138 - val_loss: 2.2007\n",
            "Epoch 549/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2196 - val_loss: 2.2203\n",
            "Epoch 550/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2122 - val_loss: 2.2115\n",
            "Epoch 551/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2141 - val_loss: 2.2221\n",
            "Epoch 552/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2102 - val_loss: 2.2117\n",
            "Epoch 553/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2172 - val_loss: 2.2235\n",
            "Epoch 554/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2195 - val_loss: 2.1928\n",
            "Epoch 555/1000\n",
            "196/196 [==============================] - 3s 14ms/step - loss: 2.2175 - val_loss: 2.2116\n",
            "Epoch 556/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2129 - val_loss: 2.2172\n",
            "Epoch 557/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2130 - val_loss: 2.2190\n",
            "Epoch 558/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2121 - val_loss: 2.2244\n",
            "Epoch 559/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2167 - val_loss: 2.2364\n",
            "Epoch 560/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2169 - val_loss: 2.2145\n",
            "Epoch 561/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2145 - val_loss: 2.2381\n",
            "Epoch 562/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2076 - val_loss: 2.2134\n",
            "Epoch 563/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2204 - val_loss: 2.2170\n",
            "Epoch 564/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2234 - val_loss: 2.2017\n",
            "Epoch 565/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2134 - val_loss: 2.2258\n",
            "Epoch 566/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2182 - val_loss: 2.2149\n",
            "Epoch 567/1000\n",
            "196/196 [==============================] - 3s 13ms/step - loss: 2.2196 - val_loss: 2.2273\n",
            "Epoch 568/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2140 - val_loss: 2.2324\n",
            "Epoch 569/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2173 - val_loss: 2.2368\n",
            "Epoch 570/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2184 - val_loss: 2.2185\n",
            "Epoch 571/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2117 - val_loss: 2.2079\n",
            "Epoch 572/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2181 - val_loss: 2.2255\n",
            "Epoch 573/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2215 - val_loss: 2.2162\n",
            "Epoch 574/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2198 - val_loss: 2.2237\n",
            "Epoch 575/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2150 - val_loss: 2.1972\n",
            "Epoch 576/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2115 - val_loss: 2.2125\n",
            "Epoch 577/1000\n",
            "196/196 [==============================] - 3s 14ms/step - loss: 2.2153 - val_loss: 2.2211\n",
            "Epoch 578/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2215 - val_loss: 2.2237\n",
            "Epoch 579/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2093 - val_loss: 2.2107\n",
            "Epoch 580/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2166 - val_loss: 2.2224\n",
            "Epoch 581/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2187 - val_loss: 2.2062\n",
            "Epoch 582/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2208 - val_loss: 2.2112\n",
            "Epoch 583/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2140 - val_loss: 2.2294\n",
            "Epoch 584/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2146 - val_loss: 2.2124\n",
            "Epoch 585/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2090 - val_loss: 2.2354\n",
            "Epoch 586/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2152 - val_loss: 2.2145\n",
            "Epoch 587/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2173 - val_loss: 2.2145\n",
            "Epoch 588/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2195 - val_loss: 2.2016\n",
            "Epoch 589/1000\n",
            "196/196 [==============================] - 3s 13ms/step - loss: 2.2105 - val_loss: 2.2085\n",
            "Epoch 590/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2175 - val_loss: 2.2202\n",
            "Epoch 591/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2188 - val_loss: 2.2154\n",
            "Epoch 592/1000\n",
            "196/196 [==============================] - 3s 13ms/step - loss: 2.2213 - val_loss: 2.2155\n",
            "Epoch 593/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2304 - val_loss: 2.2388\n",
            "Epoch 594/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2210 - val_loss: 2.2095\n",
            "Epoch 595/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2151 - val_loss: 2.1933\n",
            "Epoch 596/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2220 - val_loss: 2.2186\n",
            "Epoch 597/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2223 - val_loss: 2.2265\n",
            "Epoch 598/1000\n",
            "196/196 [==============================] - 3s 17ms/step - loss: 2.2118 - val_loss: 2.2133\n",
            "Epoch 599/1000\n",
            "196/196 [==============================] - 3s 14ms/step - loss: 2.2127 - val_loss: 2.2022\n",
            "Epoch 600/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2185 - val_loss: 2.2085\n",
            "Epoch 601/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2237 - val_loss: 2.2120\n",
            "Epoch 602/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2139 - val_loss: 2.2315\n",
            "Epoch 603/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2140 - val_loss: 2.2162\n",
            "Epoch 604/1000\n",
            "196/196 [==============================] - 3s 14ms/step - loss: 2.2210 - val_loss: 2.2195\n",
            "Epoch 605/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2231 - val_loss: 2.2052\n",
            "Epoch 606/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2164 - val_loss: 2.2133\n",
            "Epoch 607/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2109 - val_loss: 2.2073\n",
            "Epoch 608/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2161 - val_loss: 2.2089\n",
            "Epoch 609/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2160 - val_loss: 2.2063\n",
            "Epoch 610/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2130 - val_loss: 2.2025\n",
            "Epoch 611/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2168 - val_loss: 2.2184\n",
            "Epoch 612/1000\n",
            "196/196 [==============================] - 3s 17ms/step - loss: 2.2192 - val_loss: 2.2196\n",
            "Epoch 613/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2143 - val_loss: 2.2241\n",
            "Epoch 614/1000\n",
            "196/196 [==============================] - 3s 13ms/step - loss: 2.2176 - val_loss: 2.2354\n",
            "Epoch 615/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2160 - val_loss: 2.2273\n",
            "Epoch 616/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2223 - val_loss: 2.2231\n",
            "Epoch 617/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2156 - val_loss: 2.2129\n",
            "Epoch 618/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2125 - val_loss: 2.2066\n",
            "Epoch 619/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2128 - val_loss: 2.2179\n",
            "Epoch 620/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2163 - val_loss: 2.2096\n",
            "Epoch 621/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2120 - val_loss: 2.2041\n",
            "Epoch 622/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2137 - val_loss: 2.2275\n",
            "Epoch 623/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2187 - val_loss: 2.2400\n",
            "Epoch 624/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2253 - val_loss: 2.2041\n",
            "Epoch 625/1000\n",
            "196/196 [==============================] - 2s 13ms/step - loss: 2.2225 - val_loss: 2.2257\n",
            "Epoch 626/1000\n",
            "196/196 [==============================] - 3s 13ms/step - loss: 2.2161 - val_loss: 2.2132\n",
            "Epoch 627/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2189 - val_loss: 2.2222\n",
            "Epoch 628/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2186 - val_loss: 2.2246\n",
            "Epoch 629/1000\n",
            "196/196 [==============================] - 3s 13ms/step - loss: 2.2118 - val_loss: 2.2292\n",
            "Epoch 630/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2256 - val_loss: 2.2154\n",
            "Epoch 631/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2181 - val_loss: 2.2216\n",
            "Epoch 632/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2214 - val_loss: 2.2476\n",
            "Epoch 633/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2193 - val_loss: 2.2285\n",
            "Epoch 634/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2131 - val_loss: 2.2186\n",
            "Epoch 635/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2140 - val_loss: 2.2134\n",
            "Epoch 636/1000\n",
            "196/196 [==============================] - 3s 14ms/step - loss: 2.2156 - val_loss: 2.2272\n",
            "Epoch 637/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2105 - val_loss: 2.2145\n",
            "Epoch 638/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2128 - val_loss: 2.2317\n",
            "Epoch 639/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2080 - val_loss: 2.1911\n",
            "Epoch 640/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2121 - val_loss: 2.2257\n",
            "Epoch 641/1000\n",
            "196/196 [==============================] - 3s 13ms/step - loss: 2.2119 - val_loss: 2.2193\n",
            "Epoch 642/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2135 - val_loss: 2.2277\n",
            "Epoch 643/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2148 - val_loss: 2.2130\n",
            "Epoch 644/1000\n",
            "196/196 [==============================] - 2s 13ms/step - loss: 2.2097 - val_loss: 2.2101\n",
            "Epoch 645/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2075 - val_loss: 2.2271\n",
            "Epoch 646/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2143 - val_loss: 2.2183\n",
            "Epoch 647/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2143 - val_loss: 2.2288\n",
            "Epoch 648/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2210 - val_loss: 2.2030\n",
            "Epoch 649/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2128 - val_loss: 2.2109\n",
            "Epoch 650/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2165 - val_loss: 2.2189\n",
            "Epoch 651/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2183 - val_loss: 2.2241\n",
            "Epoch 652/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2171 - val_loss: 2.2268\n",
            "Epoch 653/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2153 - val_loss: 2.2161\n",
            "Epoch 654/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2151 - val_loss: 2.2239\n",
            "Epoch 655/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2129 - val_loss: 2.2069\n",
            "Epoch 656/1000\n",
            "196/196 [==============================] - 3s 14ms/step - loss: 2.2143 - val_loss: 2.2197\n",
            "Epoch 657/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2198 - val_loss: 2.1999\n",
            "Epoch 658/1000\n",
            "196/196 [==============================] - 3s 17ms/step - loss: 2.2130 - val_loss: 2.2418\n",
            "Epoch 659/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2175 - val_loss: 2.2354\n",
            "Epoch 660/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2146 - val_loss: 2.2224\n",
            "Epoch 661/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2199 - val_loss: 2.1937\n",
            "Epoch 662/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2189 - val_loss: 2.2081\n",
            "Epoch 663/1000\n",
            "196/196 [==============================] - 2s 13ms/step - loss: 2.2161 - val_loss: 2.2482\n",
            "Epoch 664/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2214 - val_loss: 2.2018\n",
            "Epoch 665/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2171 - val_loss: 2.2176\n",
            "Epoch 666/1000\n",
            "196/196 [==============================] - 3s 14ms/step - loss: 2.2189 - val_loss: 2.2138\n",
            "Epoch 667/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2153 - val_loss: 2.2209\n",
            "Epoch 668/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2179 - val_loss: 2.2285\n",
            "Epoch 669/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2227 - val_loss: 2.2147\n",
            "Epoch 670/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2108 - val_loss: 2.2262\n",
            "Epoch 671/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2091 - val_loss: 2.2283\n",
            "Epoch 672/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2120 - val_loss: 2.2093\n",
            "Epoch 673/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2121 - val_loss: 2.2194\n",
            "Epoch 674/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2174 - val_loss: 2.2277\n",
            "Epoch 675/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2169 - val_loss: 2.2143\n",
            "Epoch 676/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2080 - val_loss: 2.2002\n",
            "Epoch 677/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2165 - val_loss: 2.2088\n",
            "Epoch 678/1000\n",
            "196/196 [==============================] - 3s 14ms/step - loss: 2.2080 - val_loss: 2.1993\n",
            "Epoch 679/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2202 - val_loss: 2.2295\n",
            "Epoch 680/1000\n",
            "196/196 [==============================] - 3s 17ms/step - loss: 2.2170 - val_loss: 2.2265\n",
            "Epoch 681/1000\n",
            "196/196 [==============================] - 2s 13ms/step - loss: 2.2136 - val_loss: 2.2293\n",
            "Epoch 682/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2115 - val_loss: 2.2267\n",
            "Epoch 683/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2158 - val_loss: 2.2148\n",
            "Epoch 684/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2080 - val_loss: 2.2137\n",
            "Epoch 685/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2083 - val_loss: 2.2145\n",
            "Epoch 686/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2182 - val_loss: 2.2007\n",
            "Epoch 687/1000\n",
            "196/196 [==============================] - 3s 17ms/step - loss: 2.2126 - val_loss: 2.2219\n",
            "Epoch 688/1000\n",
            "196/196 [==============================] - 3s 14ms/step - loss: 2.2157 - val_loss: 2.2405\n",
            "Epoch 689/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2129 - val_loss: 2.2194\n",
            "Epoch 690/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2135 - val_loss: 2.2159\n",
            "Epoch 691/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2079 - val_loss: 2.2115\n",
            "Epoch 692/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2119 - val_loss: 2.1967\n",
            "Epoch 693/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2110 - val_loss: 2.2057\n",
            "Epoch 694/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2212 - val_loss: 2.2036\n",
            "Epoch 695/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2205 - val_loss: 2.2176\n",
            "Epoch 696/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2153 - val_loss: 2.2159\n",
            "Epoch 697/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2085 - val_loss: 2.2225\n",
            "Epoch 698/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2147 - val_loss: 2.2228\n",
            "Epoch 699/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2176 - val_loss: 2.1969\n",
            "Epoch 700/1000\n",
            "196/196 [==============================] - 3s 13ms/step - loss: 2.2128 - val_loss: 2.2441\n",
            "Epoch 701/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2109 - val_loss: 2.2247\n",
            "Epoch 702/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2152 - val_loss: 2.2237\n",
            "Epoch 703/1000\n",
            "196/196 [==============================] - 3s 14ms/step - loss: 2.2161 - val_loss: 2.1991\n",
            "Epoch 704/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2162 - val_loss: 2.2216\n",
            "Epoch 705/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2218 - val_loss: 2.2052\n",
            "Epoch 706/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2101 - val_loss: 2.2066\n",
            "Epoch 707/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2116 - val_loss: 2.2089\n",
            "Epoch 708/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2115 - val_loss: 2.2174\n",
            "Epoch 709/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2089 - val_loss: 2.2364\n",
            "Epoch 710/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2151 - val_loss: 2.2093\n",
            "Epoch 711/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2146 - val_loss: 2.2107\n",
            "Epoch 712/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2102 - val_loss: 2.2105\n",
            "Epoch 713/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2135 - val_loss: 2.2049\n",
            "Epoch 714/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2170 - val_loss: 2.2145\n",
            "Epoch 715/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2177 - val_loss: 2.2304\n",
            "Epoch 716/1000\n",
            "196/196 [==============================] - 3s 17ms/step - loss: 2.2178 - val_loss: 2.2195\n",
            "Epoch 717/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2055 - val_loss: 2.2137\n",
            "Epoch 718/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2165 - val_loss: 2.2197\n",
            "Epoch 719/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2146 - val_loss: 2.2129\n",
            "Epoch 720/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2152 - val_loss: 2.2203\n",
            "Epoch 721/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2164 - val_loss: 2.2013\n",
            "Epoch 722/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2102 - val_loss: 2.2186\n",
            "Epoch 723/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2123 - val_loss: 2.2089\n",
            "Epoch 724/1000\n",
            "196/196 [==============================] - 3s 17ms/step - loss: 2.2122 - val_loss: 2.2119\n",
            "Epoch 725/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2174 - val_loss: 2.2081\n",
            "Epoch 726/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2109 - val_loss: 2.2080\n",
            "Epoch 727/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2162 - val_loss: 2.2120\n",
            "Epoch 728/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2132 - val_loss: 2.2117\n",
            "Epoch 729/1000\n",
            "196/196 [==============================] - 3s 13ms/step - loss: 2.2215 - val_loss: 2.2162\n",
            "Epoch 730/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2205 - val_loss: 2.2064\n",
            "Epoch 731/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2153 - val_loss: 2.2205\n",
            "Epoch 732/1000\n",
            "196/196 [==============================] - 3s 14ms/step - loss: 2.2166 - val_loss: 2.2241\n",
            "Epoch 733/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2124 - val_loss: 2.2198\n",
            "Epoch 734/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2191 - val_loss: 2.2294\n",
            "Epoch 735/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2145 - val_loss: 2.1991\n",
            "Epoch 736/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2148 - val_loss: 2.2189\n",
            "Epoch 737/1000\n",
            "196/196 [==============================] - 3s 17ms/step - loss: 2.2090 - val_loss: 2.2283\n",
            "Epoch 738/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2152 - val_loss: 2.2051\n",
            "Epoch 739/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2240 - val_loss: 2.2046\n",
            "Epoch 740/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2215 - val_loss: 2.2166\n",
            "Epoch 741/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2186 - val_loss: 2.2075\n",
            "Epoch 742/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2137 - val_loss: 2.2292\n",
            "Epoch 743/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2192 - val_loss: 2.2225\n",
            "Epoch 744/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2131 - val_loss: 2.2225\n",
            "Epoch 745/1000\n",
            "196/196 [==============================] - 3s 17ms/step - loss: 2.2271 - val_loss: 2.2230\n",
            "Epoch 746/1000\n",
            "196/196 [==============================] - 3s 17ms/step - loss: 2.2206 - val_loss: 2.2216\n",
            "Epoch 747/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2088 - val_loss: 2.2255\n",
            "Epoch 748/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2119 - val_loss: 2.2222\n",
            "Epoch 749/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2148 - val_loss: 2.2166\n",
            "Epoch 750/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2219 - val_loss: 2.2373\n",
            "Epoch 751/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2219 - val_loss: 2.2349\n",
            "Epoch 752/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2114 - val_loss: 2.2063\n",
            "Epoch 753/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2180 - val_loss: 2.2313\n",
            "Epoch 754/1000\n",
            "196/196 [==============================] - 2s 13ms/step - loss: 2.2104 - val_loss: 2.2100\n",
            "Epoch 755/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2162 - val_loss: 2.2166\n",
            "Epoch 756/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2139 - val_loss: 2.2196\n",
            "Epoch 757/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2215 - val_loss: 2.2149\n",
            "Epoch 758/1000\n",
            "196/196 [==============================] - 3s 13ms/step - loss: 2.2168 - val_loss: 2.2194\n",
            "Epoch 759/1000\n",
            "196/196 [==============================] - 3s 17ms/step - loss: 2.2186 - val_loss: 2.2217\n",
            "Epoch 760/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2209 - val_loss: 2.2519\n",
            "Epoch 761/1000\n",
            "196/196 [==============================] - 3s 14ms/step - loss: 2.2169 - val_loss: 2.2275\n",
            "Epoch 762/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2127 - val_loss: 2.2101\n",
            "Epoch 763/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2197 - val_loss: 2.2096\n",
            "Epoch 764/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2100 - val_loss: 2.2164\n",
            "Epoch 765/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2155 - val_loss: 2.1901\n",
            "Epoch 766/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2186 - val_loss: 2.2183\n",
            "Epoch 767/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2181 - val_loss: 2.2037\n",
            "Epoch 768/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2139 - val_loss: 2.2036\n",
            "Epoch 769/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2136 - val_loss: 2.2213\n",
            "Epoch 770/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2170 - val_loss: 2.2184\n",
            "Epoch 771/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2099 - val_loss: 2.2173\n",
            "Epoch 772/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2158 - val_loss: 2.2208\n",
            "Epoch 773/1000\n",
            "196/196 [==============================] - 3s 14ms/step - loss: 2.2205 - val_loss: 2.2187\n",
            "Epoch 774/1000\n",
            "196/196 [==============================] - 3s 17ms/step - loss: 2.2119 - val_loss: 2.1967\n",
            "Epoch 775/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2116 - val_loss: 2.2185\n",
            "Epoch 776/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2138 - val_loss: 2.2119\n",
            "Epoch 777/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2216 - val_loss: 2.2079\n",
            "Epoch 778/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2101 - val_loss: 2.2341\n",
            "Epoch 779/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2122 - val_loss: 2.1979\n",
            "Epoch 780/1000\n",
            "196/196 [==============================] - 3s 13ms/step - loss: 2.2131 - val_loss: 2.2102\n",
            "Epoch 781/1000\n",
            "196/196 [==============================] - 3s 17ms/step - loss: 2.2169 - val_loss: 2.2105\n",
            "Epoch 782/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2196 - val_loss: 2.2200\n",
            "Epoch 783/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2186 - val_loss: 2.2106\n",
            "Epoch 784/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2145 - val_loss: 2.2129\n",
            "Epoch 785/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2132 - val_loss: 2.1795\n",
            "Epoch 786/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2172 - val_loss: 2.2222\n",
            "Epoch 787/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2214 - val_loss: 2.2279\n",
            "Epoch 788/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2071 - val_loss: 2.2295\n",
            "Epoch 789/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2192 - val_loss: 2.2374\n",
            "Epoch 790/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2126 - val_loss: 2.2142\n",
            "Epoch 791/1000\n",
            "196/196 [==============================] - 3s 13ms/step - loss: 2.2170 - val_loss: 2.2178\n",
            "Epoch 792/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2158 - val_loss: 2.2262\n",
            "Epoch 793/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2127 - val_loss: 2.2090\n",
            "Epoch 794/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2076 - val_loss: 2.1973\n",
            "Epoch 795/1000\n",
            "196/196 [==============================] - 3s 13ms/step - loss: 2.2085 - val_loss: 2.2168\n",
            "Epoch 796/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2212 - val_loss: 2.2207\n",
            "Epoch 797/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2132 - val_loss: 2.2270\n",
            "Epoch 798/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2194 - val_loss: 2.2201\n",
            "Epoch 799/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2135 - val_loss: 2.1969\n",
            "Epoch 800/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2111 - val_loss: 2.2071\n",
            "Epoch 801/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2194 - val_loss: 2.1858\n",
            "Epoch 802/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2196 - val_loss: 2.2513\n",
            "Epoch 803/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2213 - val_loss: 2.2123\n",
            "Epoch 804/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2135 - val_loss: 2.2210\n",
            "Epoch 805/1000\n",
            "196/196 [==============================] - 3s 17ms/step - loss: 2.2105 - val_loss: 2.2107\n",
            "Epoch 806/1000\n",
            "196/196 [==============================] - 3s 13ms/step - loss: 2.2095 - val_loss: 2.2134\n",
            "Epoch 807/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2086 - val_loss: 2.2181\n",
            "Epoch 808/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2136 - val_loss: 2.2362\n",
            "Epoch 809/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2207 - val_loss: 2.2181\n",
            "Epoch 810/1000\n",
            "196/196 [==============================] - 3s 14ms/step - loss: 2.2212 - val_loss: 2.2489\n",
            "Epoch 811/1000\n",
            "196/196 [==============================] - 3s 17ms/step - loss: 2.2165 - val_loss: 2.2077\n",
            "Epoch 812/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2125 - val_loss: 2.2305\n",
            "Epoch 813/1000\n",
            "196/196 [==============================] - 3s 14ms/step - loss: 2.2138 - val_loss: 2.2223\n",
            "Epoch 814/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2151 - val_loss: 2.2224\n",
            "Epoch 815/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2234 - val_loss: 2.2301\n",
            "Epoch 816/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2109 - val_loss: 2.2349\n",
            "Epoch 817/1000\n",
            "196/196 [==============================] - 3s 13ms/step - loss: 2.2239 - val_loss: 2.2063\n",
            "Epoch 818/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2206 - val_loss: 2.1928\n",
            "Epoch 819/1000\n",
            "196/196 [==============================] - 3s 17ms/step - loss: 2.2199 - val_loss: 2.2183\n",
            "Epoch 820/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2120 - val_loss: 2.2107\n",
            "Epoch 821/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2164 - val_loss: 2.2291\n",
            "Epoch 822/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2182 - val_loss: 2.2342\n",
            "Epoch 823/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2194 - val_loss: 2.2005\n",
            "Epoch 824/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2103 - val_loss: 2.2202\n",
            "Epoch 825/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2186 - val_loss: 2.1807\n",
            "Epoch 826/1000\n",
            "196/196 [==============================] - 3s 17ms/step - loss: 2.2094 - val_loss: 2.2126\n",
            "Epoch 827/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2142 - val_loss: 2.2341\n",
            "Epoch 828/1000\n",
            "196/196 [==============================] - 3s 13ms/step - loss: 2.2097 - val_loss: 2.2143\n",
            "Epoch 829/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2098 - val_loss: 2.2131\n",
            "Epoch 830/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2182 - val_loss: 2.2218\n",
            "Epoch 831/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2174 - val_loss: 2.2051\n",
            "Epoch 832/1000\n",
            "196/196 [==============================] - 2s 13ms/step - loss: 2.2146 - val_loss: 2.2147\n",
            "Epoch 833/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2159 - val_loss: 2.2271\n",
            "Epoch 834/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2131 - val_loss: 2.2011\n",
            "Epoch 835/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2087 - val_loss: 2.2216\n",
            "Epoch 836/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2205 - val_loss: 2.2191\n",
            "Epoch 837/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2134 - val_loss: 2.2068\n",
            "Epoch 838/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2115 - val_loss: 2.2007\n",
            "Epoch 839/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2106 - val_loss: 2.2055\n",
            "Epoch 840/1000\n",
            "196/196 [==============================] - 3s 14ms/step - loss: 2.2151 - val_loss: 2.2097\n",
            "Epoch 841/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2148 - val_loss: 2.2021\n",
            "Epoch 842/1000\n",
            "196/196 [==============================] - 3s 17ms/step - loss: 2.2168 - val_loss: 2.2270\n",
            "Epoch 843/1000\n",
            "196/196 [==============================] - 3s 13ms/step - loss: 2.2205 - val_loss: 2.2186\n",
            "Epoch 844/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2109 - val_loss: 2.2436\n",
            "Epoch 845/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2147 - val_loss: 2.2221\n",
            "Epoch 846/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2191 - val_loss: 2.2100\n",
            "Epoch 847/1000\n",
            "196/196 [==============================] - 2s 13ms/step - loss: 2.2185 - val_loss: 2.2266\n",
            "Epoch 848/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2189 - val_loss: 2.2229\n",
            "Epoch 849/1000\n",
            "196/196 [==============================] - 3s 17ms/step - loss: 2.2097 - val_loss: 2.2212\n",
            "Epoch 850/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2125 - val_loss: 2.2018\n",
            "Epoch 851/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2141 - val_loss: 2.2040\n",
            "Epoch 852/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2233 - val_loss: 2.2068\n",
            "Epoch 853/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2135 - val_loss: 2.2192\n",
            "Epoch 854/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2100 - val_loss: 2.2053\n",
            "Epoch 855/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2218 - val_loss: 2.2050\n",
            "Epoch 856/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2132 - val_loss: 2.2144\n",
            "Epoch 857/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2230 - val_loss: 2.2057\n",
            "Epoch 858/1000\n",
            "196/196 [==============================] - 3s 13ms/step - loss: 2.2127 - val_loss: 2.2328\n",
            "Epoch 859/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2180 - val_loss: 2.2267\n",
            "Epoch 860/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2147 - val_loss: 2.2025\n",
            "Epoch 861/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2222 - val_loss: 2.2210\n",
            "Epoch 862/1000\n",
            "196/196 [==============================] - 3s 13ms/step - loss: 2.2193 - val_loss: 2.2215\n",
            "Epoch 863/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2168 - val_loss: 2.2162\n",
            "Epoch 864/1000\n",
            "196/196 [==============================] - 3s 17ms/step - loss: 2.2092 - val_loss: 2.2101\n",
            "Epoch 865/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2175 - val_loss: 2.2263\n",
            "Epoch 866/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2129 - val_loss: 2.2154\n",
            "Epoch 867/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2130 - val_loss: 2.1867\n",
            "Epoch 868/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2120 - val_loss: 2.2183\n",
            "Epoch 869/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2163 - val_loss: 2.2297\n",
            "Epoch 870/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2224 - val_loss: 2.2193\n",
            "Epoch 871/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2153 - val_loss: 2.2054\n",
            "Epoch 872/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2135 - val_loss: 2.2003\n",
            "Epoch 873/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2139 - val_loss: 2.2343\n",
            "Epoch 874/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2154 - val_loss: 2.2262\n",
            "Epoch 875/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2164 - val_loss: 2.2179\n",
            "Epoch 876/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2186 - val_loss: 2.2051\n",
            "Epoch 877/1000\n",
            "196/196 [==============================] - 3s 14ms/step - loss: 2.2099 - val_loss: 2.2124\n",
            "Epoch 878/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2188 - val_loss: 2.2326\n",
            "Epoch 879/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2192 - val_loss: 2.2154\n",
            "Epoch 880/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2108 - val_loss: 2.2105\n",
            "Epoch 881/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2144 - val_loss: 2.2095\n",
            "Epoch 882/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2137 - val_loss: 2.2026\n",
            "Epoch 883/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2222 - val_loss: 2.2282\n",
            "Epoch 884/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2213 - val_loss: 2.2355\n",
            "Epoch 885/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2208 - val_loss: 2.2079\n",
            "Epoch 886/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2201 - val_loss: 2.2176\n",
            "Epoch 887/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2151 - val_loss: 2.1961\n",
            "Epoch 888/1000\n",
            "196/196 [==============================] - 2s 13ms/step - loss: 2.2194 - val_loss: 2.1926\n",
            "Epoch 889/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2204 - val_loss: 2.2116\n",
            "Epoch 890/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2174 - val_loss: 2.2230\n",
            "Epoch 891/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2192 - val_loss: 2.2131\n",
            "Epoch 892/1000\n",
            "196/196 [==============================] - 3s 13ms/step - loss: 2.2107 - val_loss: 2.2206\n",
            "Epoch 893/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2134 - val_loss: 2.2131\n",
            "Epoch 894/1000\n",
            "196/196 [==============================] - 3s 17ms/step - loss: 2.2118 - val_loss: 2.2315\n",
            "Epoch 895/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2208 - val_loss: 2.2018\n",
            "Epoch 896/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2117 - val_loss: 2.2241\n",
            "Epoch 897/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2116 - val_loss: 2.2325\n",
            "Epoch 898/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2083 - val_loss: 2.2199\n",
            "Epoch 899/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2196 - val_loss: 2.2223\n",
            "Epoch 900/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2158 - val_loss: 2.2216\n",
            "Epoch 901/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2131 - val_loss: 2.2076\n",
            "Epoch 902/1000\n",
            "196/196 [==============================] - 3s 17ms/step - loss: 2.2186 - val_loss: 2.2245\n",
            "Epoch 903/1000\n",
            "196/196 [==============================] - 3s 13ms/step - loss: 2.2124 - val_loss: 2.2316\n",
            "Epoch 904/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2224 - val_loss: 2.2294\n",
            "Epoch 905/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2141 - val_loss: 2.2369\n",
            "Epoch 906/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2159 - val_loss: 2.2035\n",
            "Epoch 907/1000\n",
            "196/196 [==============================] - 3s 13ms/step - loss: 2.2144 - val_loss: 2.1989\n",
            "Epoch 908/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2175 - val_loss: 2.2172\n",
            "Epoch 909/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2132 - val_loss: 2.2031\n",
            "Epoch 910/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2205 - val_loss: 2.2159\n",
            "Epoch 911/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2147 - val_loss: 2.2163\n",
            "Epoch 912/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2149 - val_loss: 2.2128\n",
            "Epoch 913/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2161 - val_loss: 2.2146\n",
            "Epoch 914/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2118 - val_loss: 2.2043\n",
            "Epoch 915/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2218 - val_loss: 2.2041\n",
            "Epoch 916/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2219 - val_loss: 2.2325\n",
            "Epoch 917/1000\n",
            "196/196 [==============================] - 3s 17ms/step - loss: 2.2169 - val_loss: 2.2380\n",
            "Epoch 918/1000\n",
            "196/196 [==============================] - 3s 13ms/step - loss: 2.2210 - val_loss: 2.2385\n",
            "Epoch 919/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2178 - val_loss: 2.2002\n",
            "Epoch 920/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2158 - val_loss: 2.2112\n",
            "Epoch 921/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2190 - val_loss: 2.2092\n",
            "Epoch 922/1000\n",
            "196/196 [==============================] - 3s 13ms/step - loss: 2.2127 - val_loss: 2.2246\n",
            "Epoch 923/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2112 - val_loss: 2.2069\n",
            "Epoch 924/1000\n",
            "196/196 [==============================] - 3s 17ms/step - loss: 2.2097 - val_loss: 2.2051\n",
            "Epoch 925/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2195 - val_loss: 2.2563\n",
            "Epoch 926/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2192 - val_loss: 2.2130\n",
            "Epoch 927/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2114 - val_loss: 2.2075\n",
            "Epoch 928/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2189 - val_loss: 2.2159\n",
            "Epoch 929/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2106 - val_loss: 2.2304\n",
            "Epoch 930/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2184 - val_loss: 2.2202\n",
            "Epoch 931/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2153 - val_loss: 2.2203\n",
            "Epoch 932/1000\n",
            "196/196 [==============================] - 3s 17ms/step - loss: 2.2200 - val_loss: 2.2094\n",
            "Epoch 933/1000\n",
            "196/196 [==============================] - 3s 14ms/step - loss: 2.2129 - val_loss: 2.2280\n",
            "Epoch 934/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2136 - val_loss: 2.2294\n",
            "Epoch 935/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2107 - val_loss: 2.2390\n",
            "Epoch 936/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2163 - val_loss: 2.2116\n",
            "Epoch 937/1000\n",
            "196/196 [==============================] - 3s 13ms/step - loss: 2.2072 - val_loss: 2.2225\n",
            "Epoch 938/1000\n",
            "196/196 [==============================] - 3s 14ms/step - loss: 2.2172 - val_loss: 2.1940\n",
            "Epoch 939/1000\n",
            "196/196 [==============================] - 3s 17ms/step - loss: 2.2182 - val_loss: 2.2227\n",
            "Epoch 940/1000\n",
            "196/196 [==============================] - 3s 17ms/step - loss: 2.2150 - val_loss: 2.2076\n",
            "Epoch 941/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2144 - val_loss: 2.2156\n",
            "Epoch 942/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2111 - val_loss: 2.1969\n",
            "Epoch 943/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2142 - val_loss: 2.2077\n",
            "Epoch 944/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2141 - val_loss: 2.2126\n",
            "Epoch 945/1000\n",
            "196/196 [==============================] - 3s 14ms/step - loss: 2.2192 - val_loss: 2.2318\n",
            "Epoch 946/1000\n",
            "196/196 [==============================] - 3s 17ms/step - loss: 2.2116 - val_loss: 2.2145\n",
            "Epoch 947/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2081 - val_loss: 2.1997\n",
            "Epoch 948/1000\n",
            "196/196 [==============================] - 3s 14ms/step - loss: 2.2242 - val_loss: 2.2238\n",
            "Epoch 949/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2113 - val_loss: 2.2148\n",
            "Epoch 950/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2178 - val_loss: 2.2148\n",
            "Epoch 951/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2241 - val_loss: 2.2162\n",
            "Epoch 952/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2146 - val_loss: 2.2257\n",
            "Epoch 953/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2219 - val_loss: 2.2195\n",
            "Epoch 954/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2134 - val_loss: 2.2084\n",
            "Epoch 955/1000\n",
            "196/196 [==============================] - 3s 17ms/step - loss: 2.2137 - val_loss: 2.2232\n",
            "Epoch 956/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2211 - val_loss: 2.2109\n",
            "Epoch 957/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2130 - val_loss: 2.2116\n",
            "Epoch 958/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2151 - val_loss: 2.2290\n",
            "Epoch 959/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2241 - val_loss: 2.2212\n",
            "Epoch 960/1000\n",
            "196/196 [==============================] - 3s 14ms/step - loss: 2.2188 - val_loss: 2.2265\n",
            "Epoch 961/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2128 - val_loss: 2.2110\n",
            "Epoch 962/1000\n",
            "196/196 [==============================] - 4s 18ms/step - loss: 2.2130 - val_loss: 2.2115\n",
            "Epoch 963/1000\n",
            "196/196 [==============================] - 3s 14ms/step - loss: 2.2108 - val_loss: 2.2093\n",
            "Epoch 964/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2203 - val_loss: 2.2076\n",
            "Epoch 965/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2123 - val_loss: 2.2228\n",
            "Epoch 966/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2120 - val_loss: 2.2131\n",
            "Epoch 967/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2175 - val_loss: 2.2241\n",
            "Epoch 968/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2150 - val_loss: 2.2433\n",
            "Epoch 969/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2155 - val_loss: 2.2229\n",
            "Epoch 970/1000\n",
            "196/196 [==============================] - 3s 17ms/step - loss: 2.2158 - val_loss: 2.2380\n",
            "Epoch 971/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2150 - val_loss: 2.1976\n",
            "Epoch 972/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2161 - val_loss: 2.2190\n",
            "Epoch 973/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2167 - val_loss: 2.2213\n",
            "Epoch 974/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2180 - val_loss: 2.2175\n",
            "Epoch 975/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2131 - val_loss: 2.2310\n",
            "Epoch 976/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2124 - val_loss: 2.2166\n",
            "Epoch 977/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2112 - val_loss: 2.2203\n",
            "Epoch 978/1000\n",
            "196/196 [==============================] - 3s 13ms/step - loss: 2.2181 - val_loss: 2.2084\n",
            "Epoch 979/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2177 - val_loss: 2.2250\n",
            "Epoch 980/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2164 - val_loss: 2.2111\n",
            "Epoch 981/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2163 - val_loss: 2.2402\n",
            "Epoch 982/1000\n",
            "196/196 [==============================] - 3s 13ms/step - loss: 2.2201 - val_loss: 2.1872\n",
            "Epoch 983/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2176 - val_loss: 2.2079\n",
            "Epoch 984/1000\n",
            "196/196 [==============================] - 3s 17ms/step - loss: 2.2200 - val_loss: 2.2271\n",
            "Epoch 985/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2144 - val_loss: 2.2159\n",
            "Epoch 986/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2152 - val_loss: 2.2056\n",
            "Epoch 987/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2110 - val_loss: 2.2100\n",
            "Epoch 988/1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2120 - val_loss: 2.2039\n",
            "Epoch 989/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2163 - val_loss: 2.2191\n",
            "Epoch 990/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2201 - val_loss: 2.2136\n",
            "Epoch 991/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2083 - val_loss: 2.2235\n",
            "Epoch 992/1000\n",
            "196/196 [==============================] - 3s 17ms/step - loss: 2.2123 - val_loss: 2.2341\n",
            "Epoch 993/1000\n",
            "196/196 [==============================] - 3s 14ms/step - loss: 2.2139 - val_loss: 2.2002\n",
            "Epoch 994/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2169 - val_loss: 2.2144\n",
            "Epoch 995/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2206 - val_loss: 2.2280\n",
            "Epoch 996/1000\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.2154 - val_loss: 2.2053\n",
            "Epoch 997/1000\n",
            "196/196 [==============================] - 3s 13ms/step - loss: 2.2194 - val_loss: 2.1951\n",
            "Epoch 998/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2150 - val_loss: 2.2234\n",
            "Epoch 999/1000\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 2.2165 - val_loss: 2.2057\n",
            "Epoch 1000/1000\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 2.2151 - val_loss: 2.2316\n",
            "--- 2543.6736018657684 saniye ---\n"
          ]
        }
      ],
      "source": [
        "# Training autoencoder\n",
        "t1 = time.time()\n",
        "history = autoencoder.fit(x_train, x_train,\n",
        "                epochs = 1000,\n",
        "                batch_size = 512,\n",
        "                shuffle = True,\n",
        "                validation_data = (x_test, x_test))\n",
        "print(\"--- %s saniye ---\" % (time.time() - t1))"
      ],
      "id": "95ece913"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "c436319b",
        "outputId": "ce67b1f3-ff6e-45d8-9a39-119c83202eea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['loss', 'val_loss'])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "print(history.history.keys())\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "id": "c436319b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3a85a03e"
      },
      "outputs": [],
      "source": [
        "# Encoder\n",
        "encoder = keras.Model(input_signal, Lambda1)\n",
        "\n",
        "\n",
        "# Decoder\n",
        "encoded_input = Input(shape=(2*N,))\n",
        "deco = autoencoder.layers[-2](encoded_input)\n",
        "deco = autoencoder.layers[-1](deco)\n",
        "decoder = keras.Model(encoded_input, deco)\n",
        "\n",
        "# encoder.save(\"my_encoder.h5\")\n",
        "# decoder.save(\"my_decoder.h5\")"
      ],
      "id": "3a85a03e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f233a622",
        "outputId": "f2bbaaf3-58f2-4119-e144-111585aad390"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 124ms/step\n",
            "0.9999999\n"
          ]
        }
      ],
      "source": [
        "# v = np.zeros((M,nBits))\n",
        "# for ii in range(M):\n",
        "#     a = [int(x) for x in bin(ii)[2:]]\n",
        "#     b = [int(x) for x in list('{0:0b}'.format(ii))]\n",
        "#     v[ii,nBits-len(b):nBits] = b\n",
        "\n",
        "v = np.ones(M)\n",
        "v = np.diag(v)\n",
        "SignalSet = encoder.predict(v)\n",
        "print(np.mean(np.abs(SignalSet)**2))"
      ],
      "id": "f233a622"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bdfac07",
        "outputId": "03e2dcd1-f1bb-4678-ca0b-cd0e8e395055",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.2070700370285437\n",
            "4.266366776672516\n"
          ]
        }
      ],
      "source": [
        "aa = 0\n",
        "ED = np.zeros(M*(M-1))\n",
        "for xVal in range(M):\n",
        "    for xxVal in range(M):\n",
        "        if xVal != xxVal:\n",
        "            X = SignalSet[xVal,:]\n",
        "            XX = SignalSet[xxVal,:]\n",
        "            ED[aa] = np.linalg.norm(X-XX)**2\n",
        "            aa += 1\n",
        "\n",
        "print(np.min(ED))\n",
        "print(np.mean(ED))"
      ],
      "id": "6bdfac07"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "136b4448",
        "outputId": "82ab25e8-8e19-4b91-d797-6fd4fe3d4444"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ],
      "source": [
        "scipy.io.savemat('SS_1_bps_N4_Q32_6.3898.mat', mdict={'SignalSet': SignalSet, 'Loss':history.history['loss'], 'ValLoss':history.history['val_loss']})\n",
        "decoder.compile(optimizer='adam', loss='categorical_crossentropy')\n",
        "encoder.save(\"my_encoder.h5\")\n",
        "decoder.save(\"my_decoder.h5\")"
      ],
      "id": "136b4448"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wfl4EPRAsrjy"
      },
      "outputs": [],
      "source": [],
      "id": "Wfl4EPRAsrjy"
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}